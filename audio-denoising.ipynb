{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Denoising Using Autoencoders\n",
    "\n",
    "\n",
    "Denoising Autoencoders (DAEs) are a type of artificial neural network designed to learn representations of data by reconstructing the original inputs from noisy or corrupted versions. They belong to the broader family of autoencoders, which are unsupervised learning models that learn to encode and decode data in a way that minimizes the difference between the input and the reconstructed output. DAEs have gained significant attention in the field of machine learning and deep learning due to their ability to efficiently capture the underlying structure of data while being robust to noise and corruption.\n",
    "\n",
    "The architecture of a denoising autoencoder consists of two main components: an encoder and a decoder. The encoder is responsible for transforming the noisy input data into a lower-dimensional latent representation or code. The decoder then takes this latent representation and reconstructs the original data, ideally removing the noise introduced during the encoding process.\n",
    "\n",
    "Applications of Denoising Autoencoders:\n",
    "\n",
    "1. Image denoising: DAEs have been successfully used to remove noise from images, improving their quality and making them suitable for further processing or analysis. This is especially useful in fields like medical imaging, where high-quality images are critical for accurate diagnosis.\n",
    "\n",
    "2. Feature extraction: DAEs can be used to learn meaningful and robust features from data, which can then be used as input for other machine learning tasks such as classification, clustering, or regression.\n",
    "\n",
    "3. Dimensionality reduction: DAEs can be employed to reduce the dimensionality of high-dimensional data, making it easier to visualize, analyze, and process. This can help mitigate the \"curse of dimensionality\" and improve the performance of machine learning algorithms.\n",
    "\n",
    "4. Anomaly detection: DAEs can be used to identify unusual patterns or outliers in data, as the reconstruction error will be higher for anomalies compared to typical data points. This has applications in fraud detection, network security, and quality control.\n",
    "\n",
    "5. Data imputation: DAEs can be used to fill in missing or corrupted values in datasets, thereby improving the quality of the data and enabling more accurate analysis and prediction.\n",
    "\n",
    "6. Pretraining: DAEs can be employed as a pretraining mechanism for other deep learning models, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs). By initializing the weights of these models with the learned features of a DAE, they can converge faster and achieve better performance.\n",
    "\n",
    "I want to explore denoising autoencoder's ability to denoise audio input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /home/colsonxu/anaconda3/lib/python3.10/site-packages (0.10.0.post2)\n",
      "Requirement already satisfied: pooch<1.7,>=1.0 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (0.3.5)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (1.10.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (1.2.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (65.6.3)\n",
      "Requirement already satisfied: appdirs in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: packaging in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa) (22.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from requests->pooch<1.7,>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from requests->pooch<1.7,>=1.0->librosa) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from requests->pooch<1.7,>=1.0->librosa) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/colsonxu/anaconda3/lib/python3.10/site-packages (from requests->pooch<1.7,>=1.0->librosa) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import librosa\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need a function to transform audio signal into tensor that PyTorch can process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_tensor(x):\n",
    "    out = np.expand_dims(x, axis=0)\n",
    "    if len(x.shape) == 1:\n",
    "        out = np.expand_dims(out, axis=0)\n",
    "    out = torch.from_numpy(out)\n",
    "    out = out.type(torch.Tensor)\n",
    "    out = out.permute(1, 0, 2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=32,\n",
    "            kernel_size=2048,\n",
    "            stride=32,\n",
    "            padding=1023,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "        self.synconv1 = nn.ConvTranspose1d(\n",
    "            in_channels=32,\n",
    "            out_channels=1,\n",
    "            kernel_size=2048,\n",
    "            stride=32,\n",
    "            padding=1023,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return torch.tanh(x)\n",
    "\n",
    "    def decoder(self, y):\n",
    "        return self.synconv1(y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.encoder(x)\n",
    "        return self.decoder(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1\n",
    "audio, sample_rate, = librosa.load('./sample.wav', mono=False, sr=None, offset=6)\n",
    "audio[0,:] /= np.abs(audio[0,:]).max()\n",
    "audio[1,:] /= np.abs(audio[1,:]).max()\n",
    "X_train = (signal_to_tensor(audio[0,:]) + + torch.randn(X_train.size()) * 0.05).to(device)\n",
    "X_test = signal_to_tensor(audio[1,:]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Model:\n",
      "Total number of parameters: 131105\n",
      "\n",
      "Loss function:\n",
      "output_len = 11934690\n",
      "Input X.shape = torch.Size([1, 1, 11934720])\n",
      "Target Y.shape = torch.Size([1, 1, 11934690])\n",
      "Target Y = tensor([[[ 0.0319, -0.0100,  0.0067,  ..., -0.0126,  0.0162, -0.0599]]],\n",
      "       device='cuda:0')\n",
      "Y.type() = torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate Model:\")\n",
    "model = Autoencoder().to(device)\n",
    "print('Total number of parameters:', (sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "print(\"\\nLoss function:\")\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "Ypred = model(X_train)\n",
    "   \n",
    "outputlen = len(Ypred[0,0,:])\n",
    "print(\"output_len =\", outputlen)\n",
    "    \n",
    "Y = X_train[:,:,:outputlen]\n",
    "    \n",
    "print(\"Input X.shape =\", X_train.shape )\n",
    "print(\"Target Y.shape =\", Y.shape)\n",
    "print(\"Target Y =\", Y)\n",
    "print(\"Y.type() =\", Y.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_pred = tensor([[[-0.0207, -0.0137, -0.0227,  ..., -0.0110, -0.0275,  0.0065]]],\n",
      "       device='cuda:0', grad_fn=<ConvolutionBackward0>)\n",
      "0 0.03561048209667206\n",
      "10 0.026463046669960022\n",
      "20 0.021252507343888283\n",
      "30 0.018065787851810455\n",
      "40 0.015499431639909744\n",
      "50 0.013436129316687584\n",
      "60 0.01169869676232338\n",
      "70 0.010234754532575607\n",
      "80 0.009001639671623707\n",
      "90 0.00798327848315239\n",
      "100 0.007166188210248947\n",
      "110 0.006501669529825449\n",
      "120 0.005967964418232441\n",
      "130 0.005536740645766258\n",
      "140 0.00518391327932477\n",
      "150 0.0048928027972579\n",
      "160 0.004646715242415667\n",
      "170 0.004434413276612759\n",
      "180 0.0042555020190775394\n",
      "190 0.0040961261838674545\n",
      "200 0.003955811727792025\n",
      "210 0.0038297995924949646\n",
      "220 0.003716424573212862\n",
      "230 0.0036112710367888212\n",
      "240 0.0035157857928425074\n",
      "250 0.0034249690361320972\n",
      "260 0.0033420000690966845\n",
      "270 0.00326350424438715\n",
      "280 0.0031897155568003654\n",
      "290 0.0031194838229566813\n",
      "300 0.0030535853002220392\n",
      "310 0.0029890609439462423\n",
      "320 0.0029289317317306995\n",
      "330 0.002869205316528678\n",
      "340 0.0028123613446950912\n",
      "350 0.002758129732683301\n",
      "360 0.002705934690311551\n",
      "370 0.002655140357092023\n",
      "380 0.002606903901323676\n",
      "390 0.0025588569696992636\n",
      "400 0.002513607731088996\n",
      "410 0.0024681228678673506\n",
      "420 0.0024239574559032917\n",
      "430 0.002382025821134448\n",
      "440 0.00234123133122921\n",
      "450 0.002301457105204463\n",
      "460 0.002263336442410946\n",
      "470 0.002225245349109173\n",
      "480 0.0021890911739319563\n",
      "490 0.00215262733399868\n",
      "500 0.002116904128342867\n",
      "510 0.002083037281408906\n",
      "520 0.0020498051308095455\n",
      "530 0.002017681486904621\n",
      "540 0.0019863906782120466\n",
      "550 0.0019553559832274914\n",
      "560 0.001925577176734805\n",
      "570 0.0018955948762595654\n",
      "580 0.001866085804067552\n",
      "590 0.0018380368128418922\n",
      "600 0.0018103830516338348\n",
      "610 0.001783941057510674\n",
      "620 0.0017576036043465137\n",
      "630 0.0017319358885288239\n",
      "640 0.001706906477920711\n",
      "650 0.0016818736912682652\n",
      "660 0.0016571070300415158\n",
      "670 0.001633490202948451\n",
      "680 0.001610209234058857\n",
      "690 0.001588106737472117\n",
      "700 0.0015655341558158398\n",
      "710 0.0015440742718055844\n",
      "720 0.0015227380208671093\n",
      "730 0.0015015933895483613\n",
      "740 0.0014805067330598831\n",
      "750 0.0014603749150410295\n",
      "760 0.001440595369786024\n",
      "770 0.0014218740398064256\n",
      "780 0.001402255380526185\n",
      "790 0.001384122297167778\n",
      "800 0.00136570876929909\n",
      "810 0.0013476649764925241\n",
      "820 0.0013294684467837214\n",
      "830 0.0013121346710249782\n",
      "840 0.0012951501412317157\n",
      "850 0.0012790746986865997\n",
      "860 0.0012618324253708124\n",
      "870 0.0012463151942938566\n",
      "880 0.0012302413815632463\n",
      "890 0.001214665244333446\n",
      "900 0.0011987556936219335\n",
      "910 0.0011836969060823321\n",
      "920 0.0011689316015690565\n",
      "930 0.001154945814050734\n",
      "940 0.0011396422050893307\n",
      "950 0.0011261648032814264\n",
      "960 0.0011119727278128266\n",
      "970 0.0010983806569129229\n",
      "980 0.0010843077907338738\n",
      "990 0.0010710968635976315\n",
      "1000 0.0010580990929156542\n",
      "1010 0.001045771175995469\n",
      "1020 0.001032081781886518\n",
      "1030 0.0010201988043263555\n",
      "1040 0.0010075245518237352\n",
      "1050 0.000995549838989973\n",
      "1060 0.0009829768678173423\n",
      "1070 0.000971267290879041\n",
      "1080 0.0009597075986675918\n",
      "1090 0.0009487150236964226\n",
      "1100 0.0009363872231915593\n",
      "1110 0.0009257796918973327\n",
      "1120 0.000914340082090348\n",
      "1130 0.0009036982082761824\n",
      "1140 0.000892383512109518\n",
      "1150 0.0008819153299555182\n",
      "1160 0.0008715495932847261\n",
      "1170 0.0008616569684818387\n",
      "1180 0.0008505021687597036\n",
      "1190 0.0008409301517531276\n",
      "1200 0.0008305406663566828\n",
      "1210 0.0008210132364183664\n",
      "1220 0.0008107947069220245\n",
      "1230 0.0008013594779185951\n",
      "1240 0.0007920183707028627\n",
      "1250 0.0007830382674001157\n",
      "1260 0.0007729138596914709\n",
      "1270 0.0007641965057700872\n",
      "1280 0.0007547257700935006\n",
      "1290 0.0007461650529876351\n",
      "1300 0.0007369027589447796\n",
      "1310 0.0007283407030627131\n",
      "1320 0.0007198953535407782\n",
      "1330 0.0007116934284567833\n",
      "1340 0.0007024875958450139\n",
      "1350 0.0006944951601326466\n",
      "1360 0.0006858578999526799\n",
      "1370 0.0006781240808777511\n",
      "1380 0.0006697066128253937\n",
      "1390 0.0006618995103053749\n",
      "1400 0.0006542396149598062\n",
      "1410 0.000646713306196034\n",
      "1420 0.0006383440922945738\n",
      "1430 0.0006309624877758324\n",
      "1440 0.0006231043953448534\n",
      "1450 0.000616078672464937\n",
      "1460 0.0006084199994802475\n",
      "1470 0.00060127186588943\n",
      "1480 0.000594295677728951\n",
      "1490 0.0005873680347576737\n",
      "1500 0.0005797518533654511\n",
      "1510 0.0005729038384743035\n",
      "1520 0.0005657717119902372\n",
      "1530 0.0005593692767433822\n",
      "1540 0.0005523652653209865\n",
      "1550 0.0005458176601678133\n",
      "1560 0.0005394412437453866\n",
      "1570 0.0005330345593392849\n",
      "1580 0.0005261020851321518\n",
      "1590 0.0005197206628508866\n",
      "1600 0.000513268169015646\n",
      "1610 0.0005073862848803401\n",
      "1620 0.000500972499139607\n",
      "1630 0.0004949637805111706\n",
      "1640 0.0004891116986982524\n",
      "1650 0.0004831721307709813\n",
      "1660 0.00047684801393188536\n",
      "1670 0.00047089019790291786\n",
      "1680 0.000465058081317693\n",
      "1690 0.0004596203798428178\n",
      "1700 0.00045372862950898707\n",
      "1710 0.0004481932846829295\n",
      "1720 0.000442811637185514\n",
      "1730 0.000437288690591231\n",
      "1740 0.0004315124242566526\n",
      "1750 0.00042593583930283785\n",
      "1760 0.00042065122397616506\n",
      "1770 0.00041559230885468423\n",
      "1780 0.0004101512022316456\n",
      "1790 0.0004050469142384827\n",
      "1800 0.00040009248186834157\n",
      "1810 0.00039492256473749876\n",
      "1820 0.00038963722181506455\n",
      "1830 0.00038440446951426566\n",
      "1840 0.00037960827467031777\n",
      "1850 0.00037486437940970063\n",
      "1860 0.00036983503377996385\n",
      "1870 0.0003651071747299284\n",
      "1880 0.00036054995143786073\n",
      "1890 0.0003556858573574573\n",
      "1900 0.0003508389345370233\n",
      "1910 0.00034592789597809315\n",
      "1920 0.00034156339825131\n",
      "1930 0.0003371001803316176\n",
      "1940 0.00033242805511690676\n",
      "1950 0.00032804679358378053\n",
      "1960 0.0003238623612560332\n",
      "1970 0.0003192825533915311\n",
      "1980 0.0003148399409838021\n",
      "1990 0.00031023460905998945\n",
      "2000 0.00030625934596173465\n",
      "2010 0.0003020500880666077\n",
      "2020 0.00029771795379929245\n",
      "2030 0.0002936704840976745\n",
      "2040 0.0002898328530136496\n",
      "2050 0.00028552499134093523\n",
      "2060 0.0002814787731040269\n",
      "2070 0.00027716567274183035\n",
      "2080 0.00027354402118362486\n",
      "2090 0.0002695804287213832\n",
      "2100 0.00026559323305264115\n",
      "2110 0.0002618510916363448\n",
      "2120 0.00025836119311861694\n",
      "2130 0.0002543478331062943\n",
      "2140 0.0002506787423044443\n",
      "2150 0.0002466534497216344\n",
      "2160 0.00024338951334357262\n",
      "2170 0.00023966209846548736\n",
      "2180 0.0002360247599426657\n",
      "2190 0.00023261329624801874\n",
      "2200 0.00022945077216718346\n",
      "2210 0.00022573360183741897\n",
      "2220 0.00022243916464503855\n",
      "2230 0.00021871978242415935\n",
      "2240 0.00021578525775112212\n",
      "2250 0.00021232158178463578\n",
      "2260 0.00020904182747472078\n",
      "2270 0.00020594029047060758\n",
      "2280 0.00020309514366090298\n",
      "2290 0.0001997014187509194\n",
      "2300 0.0001967598363989964\n",
      "2310 0.0001933429593918845\n",
      "2320 0.00019073997100349516\n",
      "2330 0.00018753265612758696\n",
      "2340 0.00018460082355886698\n",
      "2350 0.00018179990001954138\n",
      "2360 0.00017927437147591263\n",
      "2370 0.00017620607104618102\n",
      "2380 0.000173582520801574\n",
      "2390 0.00017048347217496485\n",
      "2400 0.00016818306175991893\n",
      "2410 0.0001652213541092351\n",
      "2420 0.0001626290031708777\n",
      "2430 0.0001601255644345656\n",
      "2440 0.00015787783195264637\n",
      "2450 0.00015511721721850336\n",
      "2460 0.0001527869753772393\n",
      "2470 0.00014998075494077057\n",
      "2480 0.00014794569869991392\n",
      "2490 0.00014524876314681023\n",
      "2500 0.00014295252913143486\n",
      "2510 0.00014072553312871605\n",
      "2520 0.00013871482224203646\n",
      "2530 0.00013623066479340196\n",
      "2540 0.00013414231943897903\n",
      "2550 0.00013162648247089237\n",
      "2560 0.0001298229763051495\n",
      "2570 0.00012734833580907434\n",
      "2580 0.00012531294487416744\n",
      "2590 0.00012332486221566796\n",
      "2600 0.00012150557449785993\n",
      "2610 0.00011927125160582364\n",
      "2620 0.00011738370812963694\n",
      "2630 0.0001151170872617513\n",
      "2640 0.0001134898848249577\n",
      "2650 0.00011123297008452937\n",
      "2660 0.0001094171020668\n",
      "2670 0.00010763657337520272\n",
      "2680 0.00010596204811008647\n",
      "2690 0.00010394579294370487\n",
      "2700 0.00010221939737675712\n",
      "2710 0.0001001731216092594\n",
      "2720 9.86917584668845e-05\n",
      "2730 9.66346196946688e-05\n",
      "2740 9.499878069618717e-05\n",
      "2750 9.339778625871986e-05\n",
      "2760 9.18474979698658e-05\n",
      "2770 9.003506420413032e-05\n",
      "2780 8.845036791171879e-05\n",
      "2790 8.660623279865831e-05\n",
      "2800 8.526154124410823e-05\n",
      "2810 8.339768828591332e-05\n",
      "2820 8.191978122340515e-05\n",
      "2830 8.049106691032648e-05\n",
      "2840 7.906236714916304e-05\n",
      "2850 7.744464528514072e-05\n",
      "2860 7.599416858283803e-05\n",
      "2870 7.436803571181372e-05\n",
      "2880 7.3151575634256e-05\n",
      "2890 7.149335579015315e-05\n",
      "2900 7.018298492766917e-05\n",
      "2910 6.891565135447308e-05\n",
      "2920 6.761398981325328e-05\n",
      "2930 6.620932254008949e-05\n",
      "2940 6.489998486358672e-05\n",
      "2950 6.348572787828743e-05\n",
      "2960 6.241878145374358e-05\n",
      "2970 6.0967926401644945e-05\n",
      "2980 5.980940113659017e-05\n",
      "2990 5.872507972526364e-05\n",
      "3000 5.754845551564358e-05\n",
      "3010 5.634661647491157e-05\n",
      "3020 5.519861952052452e-05\n",
      "3030 5.400091322371736e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3040 5.306982347974554e-05\n",
      "3050 5.182927634450607e-05\n",
      "3060 5.0817227020161226e-05\n",
      "3070 4.9894839321495965e-05\n",
      "3080 4.886571332463063e-05\n",
      "3090 4.78734182252083e-05\n",
      "3100 4.722706580650993e-05\n",
      "3110 4.5868375309510157e-05\n",
      "3120 4.5031512854620814e-05\n",
      "3130 4.399488170747645e-05\n",
      "3140 4.313085810281336e-05\n",
      "3150 4.233764411765151e-05\n",
      "3160 4.145746061112732e-05\n",
      "3170 4.0863571484806016e-05\n",
      "3180 3.973747880081646e-05\n",
      "3190 3.886838021571748e-05\n",
      "3200 3.818239929387346e-05\n",
      "3210 3.731169999809936e-05\n",
      "3220 3.657759589259513e-05\n",
      "3230 3.5971035686088726e-05\n",
      "3240 3.5312627005623654e-05\n",
      "3250 3.441362059675157e-05\n",
      "3260 3.369833211763762e-05\n",
      "3270 3.321616895846091e-05\n",
      "3280 3.264249244239181e-05\n",
      "3290 3.1689240131527185e-05\n",
      "3300 3.107531665591523e-05\n",
      "3310 3.054592161788605e-05\n",
      "3320 2.9897555577917956e-05\n",
      "3330 2.9500768505386077e-05\n",
      "3340 2.8720005502691492e-05\n",
      "3350 2.816094274749048e-05\n",
      "3360 2.7641472115647048e-05\n",
      "3370 2.713087815209292e-05\n",
      "3380 2.7703526939149015e-05\n",
      "3390 2.643613152031321e-05\n",
      "3400 2.5643619665061124e-05\n",
      "3410 2.5176603230647743e-05\n",
      "3420 2.467999183863867e-05\n",
      "3430 2.4253802621387877e-05\n",
      "3440 2.3877297280705534e-05\n",
      "3450 2.379837133048568e-05\n",
      "3460 2.379327816015575e-05\n",
      "3470 2.2938334950595163e-05\n",
      "3480 2.243759809061885e-05\n",
      "3490 2.192990177718457e-05\n",
      "3500 2.1550935343839228e-05\n",
      "3510 2.125206810887903e-05\n",
      "3520 2.0926860088366084e-05\n",
      "3530 2.0610941646737047e-05\n",
      "3540 2.032701922871638e-05\n",
      "3550 2.051644514722284e-05\n",
      "3560 2.0029308871016838e-05\n",
      "3570 1.9872886696248315e-05\n",
      "3580 1.9187302314094268e-05\n",
      "3590 1.9020983017981052e-05\n",
      "3600 1.8719390936894342e-05\n",
      "3610 1.84868822543649e-05\n",
      "3620 1.8578964954940602e-05\n",
      "3630 1.811507718230132e-05\n",
      "3640 1.7824013411882333e-05\n",
      "3650 1.762568899721373e-05\n",
      "3660 1.7853100871434435e-05\n",
      "3670 1.7237718566320837e-05\n",
      "3680 1.7002566892188042e-05\n",
      "3690 1.687451367615722e-05\n",
      "3700 1.704149144643452e-05\n",
      "3710 1.651760976528749e-05\n",
      "3720 1.631844133953564e-05\n",
      "3730 1.619845897948835e-05\n",
      "3740 1.605538636795245e-05\n",
      "3750 1.595883077243343e-05\n",
      "3760 1.568078005220741e-05\n",
      "3770 1.574938141857274e-05\n",
      "3780 1.5884870663285255e-05\n",
      "3790 1.569538471812848e-05\n",
      "3800 1.50922724060365e-05\n",
      "3810 1.4965575246606022e-05\n",
      "3820 1.4745779481017962e-05\n",
      "3830 1.4643469512520824e-05\n",
      "3840 1.4637149433838204e-05\n",
      "3850 1.5065555089677218e-05\n",
      "3860 1.4455897144216578e-05\n",
      "3870 1.4343262591864914e-05\n",
      "3880 1.5051162336021662e-05\n",
      "3890 1.420643638994079e-05\n",
      "3900 1.3891287380829453e-05\n",
      "3910 1.371228245261591e-05\n",
      "3920 1.3557733836933039e-05\n",
      "3930 1.3464278708852362e-05\n",
      "3940 1.4016636669111904e-05\n",
      "3950 1.339564460067777e-05\n",
      "3960 1.3282154213811737e-05\n",
      "3970 1.3156573913875036e-05\n",
      "3980 1.3081108590995427e-05\n",
      "3990 1.300171970797237e-05\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "Y_pred = model(X_train)\n",
    "print(\"Y_pred =\", Y_pred)\n",
    "\n",
    "# True for optimization of random direction, False for pytorch optimization\n",
    "randdir = False\n",
    "    \n",
    "if randdir == True:\n",
    "    # optimization of weights using method of random directions:\n",
    "    optimrandomdir_pytorch.optimizer(\n",
    "        model,\n",
    "        loss_fn,\n",
    "        X_train,\n",
    "        Y,\n",
    "        iterations=100000,\n",
    "        startingscale=0.25,\n",
    "        endscale=0.0\n",
    "    )\n",
    "else:\n",
    "    for epoch in range(4000):\n",
    "        # distortions: shift and noise:\n",
    "        Xlast = X_train[:,:,-1].clone() \n",
    "        X_train[:,:,1:] = X_train[:,:,:-1].clone() # round Robbin, shift 1 right\n",
    "        X_train[:,:,0] = Xlast.clone()\n",
    "        Ylast = Y[:,:,-1].clone() \n",
    "        Y[:,:,1:] = Y[:,:,:-1].clone() # round Robbin, shift 1 right\n",
    "        Y[:,:,0] = Ylast.clone()\n",
    "\n",
    "        Ypred = model(X_train)\n",
    "        loss = loss_fn(Ypred, Y)\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch, loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
